---
author: Daniel Wysocki
title: Hidden Markov Music
output:
  beamer_presentation:
    theme: CambridgeUS
    colortheme: dolphin
    fonttheme: serif
    includes:
      in_header: [hidden-markov-music-quest-header.tex]
---

```{r echo=FALSE, message=FALSE}
require(knitcitations)
cleanbib()
bib <- read.bibtex("hidden-markov-music-quest.bib")
```

# Algorithmic Composition

## Knowledge-based Systems

- follow a set of rules defined by the programmer
- depends on knowledge of the programmer

## Machine Learning

- existing compositions are used to create a model
- new compositions are produced based on the model
    - deterministic
    - probabilistic
- challenging to find a model which captures the essence of music


# Markov Processes

## Definition

- the future depends only on the present
- nondeterministic
- may not perfectly represent the system being modeled
    - often serves as a good approximation

## Markov Chain

\begin{figure}
\centering
\markovchain
\end{figure}

## Training a Markov Chain

- to train a Markov chain, simply count the occurences of each transition
- divide each element by its row's total

\begin{figure}
\begin{tabular}{r||c|c|c}
& G & Y & R
\\\hline\hline
G & 45 & 5 & 0
\\\hline
Y & 0 & 25 & 25
\\\hline
R & 30 & 0 & 20
\end{tabular}
$\Rightarrow$
\begin{tabular}{r||c|c|c}
& G & Y & R
\\\hline\hline
G & 0.9 & 0.1 & 0
\\\hline
Y & 0 & 0.5 & 0.5
\\\hline
R & 0.6 & 0 & 0.4
\end{tabular}
\end{figure}


## Hidden Markov Model

- Marvin the Martian is looking down at a traffic light from space
- he cannot see the actual lights, but instead he sees the speed and direction
  of the cars
- he can still model the traffic light, using an HMM


## Hidden Markov Model Example

\begin{figure}
\centering
\hiddenmarkovmodel
\end{figure}


# Hidden Markov Music

## Overview

- we model songs as Markov processes
- notes are observed
- some underlying states of the song are hidden from us
    - we choose the number of states, and everything else is automatic
- we train the model on a song
    - allows us to generate new songs (algorithmic composition)


## Model

\begin{figure}
\centering
\hiddenmarkovmusic
\end{figure}

## First Song

- trained a model on Twinkle, Twinkle, Little Star

\includemedia[
  addresource={audio/twinkle.mp3},
  flashvars={
    source={audio/twinkle.mp3}
   &autoPlay=true
  }
]{\fbox{Play}}{APlayer.swf}

- produced the following song

\includemedia[
  addresource={audio/first-song.mp3},
  flashvars={
    source={audio/first-song.mp3}
   &autoPlay=true
  }
]{\fbox{Play}}{APlayer.swf}



## Für Elise

- trained a model on Beethoven's Für Elise

- using 5 states

- using 15 states

## Composer Models

- want to train models on composers, not just individual songs
- training algorithm only works on a single song at a time
- can join the songs together, but loses information


## Acknowlegements

Special thanks to Craig Graci, and Andrey Markov


## Questions?

Listen to more pieces here
\begin{figure}[b]
  \centering
  \includegraphics[width=0.35\textwidth]{img/qr-music}

  \href{https://dwysocki.github.io/csc466/music.html}
       {https://dwysocki.github.io/csc466/music.html}
\end{figure}

## Bonus Samples

- *add some extra samples in case time permits*
